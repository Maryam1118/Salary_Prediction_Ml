# -*- coding: utf-8 -*-
"""Salary prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11XKtRI-reIOAMcgQ3mfOpUUgRfm_2Bn-
"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

import joblib

df = pd.read_csv("Salary Data.csv")

print(df.head())
print("\nShape:", df.shape)
print("\nMissing Values:\n", df.isnull().sum())

TARGET = "Salary"

X = df.drop(TARGET, axis=1)
y = df[TARGET]

num_features = X.select_dtypes(include=["int64", "float64"]).columns
cat_features = X.select_dtypes(include=["object"]).columns

print("Numerical Columns:", list(num_features))
print("Categorical Columns:", list(cat_features))

numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="mean")),
    ("scaler", StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("encoder", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, num_features),
        ("cat", categorical_transformer, cat_features)
    ]
)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(random_state=42),
    "Random Forest": RandomForestRegressor(n_estimators=200, random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(random_state=42)
}

results = []

# Filter out rows with missing target values from training and testing sets
train_mask = y_train.notna()
X_train_clean = X_train[train_mask]
y_train_clean = y_train[train_mask]

test_mask = y_test.notna()
X_test_clean = X_test[test_mask]
y_test_clean = y_test[test_mask]

for name, model in models.items():

    pipe = Pipeline(steps=[
        ("preprocess", preprocessor),
        ("model", model)
    ])

    # Fit the model using the cleaned training data
    pipe.fit(X_train_clean, y_train_clean)

    # Predict using the cleaned test features
    y_pred = pipe.predict(X_test_clean)

    # Calculate metrics using the cleaned test labels
    mae = mean_absolute_error(y_test_clean, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test_clean, y_pred))
    r2 = r2_score(y_test_clean, y_pred)

    results.append({
        "Model": name,
        "MAE": mae,
        "RMSE": rmse,
        "R2": r2
    })

    print(f"\n{name}")
    print("MAE:", mae)
    print("RMSE:", rmse)
    print("R2:", r2)

results_df = pd.DataFrame(results)

print("\nMODEL COMPARISON:\n")
print(results_df.sort_values(by="RMSE"))

best_pipe = Pipeline(steps=[
    ("preprocess", preprocessor),
    ("model", RandomForestRegressor(n_estimators=200, random_state=42))
])

# Use the cleaned data (without NaNs in the target) created in the evaluation step
best_pipe.fit(X_train_clean, y_train_clean)

joblib.dump(best_pipe, "salary_prediction_model.pkl")

print("âœ… Model saved successfully")

new_employee = pd.DataFrame({
    "Years of Experience": [5],
    "Education Level": ["Masters"],
    "Job Title": ["Data Scientist"],
    "Age": ["30"],
    "Gender": ["Male"]
})

loaded_model = joblib.load("salary_prediction_model.pkl")

salary = loaded_model.predict(new_employee)

print("ðŸ’° Predicted Salary:", salary[0])